{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b55bf8-5817-4ee4-9f00-9a1837315ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger('metaanalyser').setLevel(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88857d3d-6a25-4f13-8f98-8d9e813c4aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b740aa5d-9c5f-4cff-a011-e448d5199e15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.sr:Searching `programming testing arxiv` on Google Scholar.\n",
      "INFO:metaanalyser.paper.paper:Looking for `programming testing arxiv` on Google Scholar, offset: 0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SRChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.paper.paper:Collecting details...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f4f87dbf7a4d5386f4ea157197fc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.sr:Writing an overview of the paper.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SROverviewChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.paper.paper:Number of papers: 5, number of tokens: 1316, text: Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Summry: In ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "Human: Write an overview of the systematic review based on the summary of the following list of paper abstracts.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Summry: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Summry: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Summry: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Summry: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Summry: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "-----\n",
      "\n",
      "This overview should serve as a compass for you as you construct the outline of the systematic review and write down its details.\n",
      "\n",
      "Assuming that the readers of this systematic review will not be familiar with the field. In order to make it easy for readers who are not familiar with this field to understand, list the main points briefly (approximately 30 words maximum) based on the following points.\n",
      "\n",
      "- Motivation for this field and the problem this field are trying to solve\n",
      "- Historical background of this field\n",
      "- Future development of this field\n",
      "\n",
      "Based on these main points, provide an overview of the systematic review regarding programming testing arxiv you will write.\n",
      "\n",
      "Finally, write the title of the systematic review you are going to write based on this overview.\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"title\": {\"title\": \"Title\", \"description\": \"title of the systematic review\", \"type\": \"string\"}, \"main_points\": {\"title\": \"Main Points\", \"description\": \"main points that make up the systematic review\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"overview\": {\"title\": \"Overview\", \"description\": \"overview of the systematic review\", \"type\": \"string\"}}, \"required\": [\"title\", \"main_points\", \"overview\"]}\n",
      "```\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 1755, 'completion_tokens': 204, 'total_tokens': 1959}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Building the outline of the paper.\n",
      "INFO:metaanalyser.paper.paper:Number of papers: 5, number of tokens: 1316, text: Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Summry: In ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SROutlintChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "Human: Build an outline of the systematic review regarding \"programming testing arxiv\" based on the following list of paper abstracts.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Summry: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Summry: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Summry: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Summry: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Summry: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "-----\n",
      "\n",
      "The following is an overview of this systematic review. Build the outline of the systematic review according to this overview.\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "-----\n",
      "\n",
      "Device each section of this outline by citing abstracts from the papers.\n",
      "The beginning of element of the sections should by titled \"Introduction\" and last element of the sections should be titled \"Conclusion\".\n",
      "It is preferred that sections be divided into more child sections. Each section can have up to two child sections.\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"sections\": {\"title\": \"Sections\", \"description\": \"sections that make up this systematic review\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Section\"}}, \"citations_ids\": {\"title\": \"Citations Ids\", \"description\": \"citation ids to all paper abstracts cited in this paper\", \"type\": \"array\", \"items\": {\"type\": \"integer\"}}}, \"required\": [\"sections\", \"citations_ids\"], \"definitions\": {\"Section\": {\"title\": \"Section\", \"type\": \"object\", \"properties\": {\"title\": {\"title\": \"Title\", \"description\": \"title of this section\", \"type\": \"string\"}, \"children\": {\"title\": \"Children\", \"description\": \"subsections of this section\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Section\"}}, \"description\": {\"title\": \"Description\", \"description\": \"brief description of this section (approximately 30 words maximum)\", \"type\": \"string\"}, \"citation_ids\": {\"title\": \"Citation Ids\", \"description\": \"citation ids to a paper abstract that this section cites\", \"type\": \"array\", \"items\": {\"type\": \"integer\"}}}, \"required\": [\"title\", \"description\", \"citation_ids\"]}}}\n",
      "```\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2053, 'completion_tokens': 1306, 'total_tokens': 3359}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Creating vector store.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.paper.vectorstore:Creating vector store, tiktoken_encoder_model_name='gpt-3.5-turbo', chunk_size=150, chunk_overlap=10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09179d8963094d8a9f03d7c9feac4fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.text_splitter:Created a chunk of size 262, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 182, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 174, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 171, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 151, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 196, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 165, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 199, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 169, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 188, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 170, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 194, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 235, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 161, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 169, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 227, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 157, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 242, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 217, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 343, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 207, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 244, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 258, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 195, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 197, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 253, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 158, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 374, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 251, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 987, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 714, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 254, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 263, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 494, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 168, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 227, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 423, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 212, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 237, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 248, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 186, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 161, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 186, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 206, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 183, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 446, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 176, which is longer than the specified 150\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 670, which is longer than the specified 150\n",
      "INFO:metaanalyser.paper.vectorstore:Vector store is created from 10 papers, document size=1259\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [1 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Introduction\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 2 level markdown title (`##`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2528, 'completion_tokens': 294, 'total_tokens': 2822}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [2 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Metamorphic Testing for Generating Next Test Cases\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: We call this approach  because new test cases are evolved from the old  Metamorphic Testing  ones that are normally selected according to some existing selection criteria including the random  selection strategy4  We wish to point out that metamorphic testing is to be used with other test case selection  strategies4 Based on each test case selected according to a speci/c strategy and its output result: a  number of new test cases can be designed to further test the software and increase our con/dence  in the software4  Furthermore: metamorphic testing can also be combined with Blum<s program  checker which stops after the veri/cation of the corresponding output is done but does not suggest  further testing4\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In this paper, only the Erst type  of errors will be discussed0 A comprehensive treatment of the detection of other errors in numerical  problems using metamorphic testing can be found in GHI0  The idea for using metamorphic testing comes from the fact that if we prepare a new input pair  by interchanging any two rows of  and the corresponding entries of  , the output will be the same  A  b  as the output given the original input pair +  ,  -0\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: As metamorphic testing requires problem domain knowledge in general8 we expect that a domain  speciAc methodology should be developed4 To facilitate the development of such a methodology8 we  are studying various criteria of classifying programs into their appropriate domains4  Acknowledgements  We would like to thank F4T4 Chan and M4F4 Lau for helpful discussion on the paper4 In particular8  example H is extracted and modiAed from an example in a manuscript by Chan8 Lau8 and the  authors44  References  IJK M4 Blum8 @Program Checking@8  Foundations of Software Technology and Theoretical Computer  Science  8 Lecture Notes in Computer Science8 Vol4\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In this paper, we propose a novel test case selection technique that derives new  test cases from the successful ones4 The selection aims at revealing software errors that are possibly  left undetected in successful test cases which may be generated using some existing strategies4 As  such, the proposed technique augments the eFectiveness of existing test selection strategies4 The  y  This pro ject was partially supported by a grant from the Australian Research Council and the Hong Kong Research  Grant Council<  x    Corresponding Author  G  \f",
      "technique also helps uncover software errors in the production phase and can be used in the absence  of test oracles3    Keywords  4 Selection of Test Cases8 Software Quality8\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: Published as Technical Report HKUST-CS98-01, Department of Computer Science  The Hong Kong University of Science and Technology, 1998.    Metamorphic Testing/  A New Approach for Generating Next Test Cases  y  Department of Computer Science3  The University of Melbourne  T!  Y!  Chen  Parkville =>?  @3 Australia  BtycCcs!mu!oz!auE  S!  C!  Cheung  x  Department of Computer Science3 The Hong Kong University of Science and Technology  Clear Water Bay3 Kowloon3 Hong Kong  BsccCcs!ust!hkE  S! M! Yiu  Department of Computer Science3\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: As metamorphic testing generally requires the use of problem domain knowledge: the approach  is illustrated using several program examples4 Section B states the preliminaries and examples are  presented in Section N4 Concluding remarks are presented in Section O4    Preliminaries  Given a program  and a test case  : the corresponding output is denoted by  @  D4 Assume  is  P  x  P  x  x  a test case with output  @  D4 Our approach is to construct a number of new test cases  :  :  :  P  x  x  x  $ $ $  !\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: Calculate solution vector x6 78 EIFcG should be obtained 87   M! P    Conclusion  In this paper* we have proposed a new approach for generating test cases called  3  Metamorphic Testing  This approach aims at uncovering those errors which are commonly found in similar applications3  Test cases are generated according to the input8output pair of an 9apparently: successful test case*  which is selected using some well known criteria3 The test cases generated target those errors which  are possibly left undetected by the previous successful test case3 Metamorphic Testing enables soft8  ware practitioners to design additional tests and hence improve the software reliability3\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 2 level markdown title (`##`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2702, 'completion_tokens': 262, 'total_tokens': 2964}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [3 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Background\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Background: This subsection provides a brief history of software testing and its importance in software development.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2520, 'completion_tokens': 218, 'total_tokens': 2738}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [4 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Metamorphic Testing\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: We call this approach  because new test cases are evolved from the old  Metamorphic Testing  ones that are normally selected according to some existing selection criteria including the random  selection strategy4  We wish to point out that metamorphic testing is to be used with other test case selection  strategies4 Based on each test case selected according to a speci/c strategy and its output result: a  number of new test cases can be designed to further test the software and increase our con/dence  in the software4  Furthermore: metamorphic testing can also be combined with Blum<s program  checker which stops after the veri/cation of the corresponding output is done but does not suggest  further testing4\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: As metamorphic testing requires problem domain knowledge in general8 we expect that a domain  speciAc methodology should be developed4 To facilitate the development of such a methodology8 we  are studying various criteria of classifying programs into their appropriate domains4  Acknowledgements  We would like to thank F4T4 Chan and M4F4 Lau for helpful discussion on the paper4 In particular8  example H is extracted and modiAed from an example in a manuscript by Chan8 Lau8 and the  authors44  References  IJK M4 Blum8 @Program Checking@8  Foundations of Software Technology and Theoretical Computer  Science  8 Lecture Notes in Computer Science8 Vol4\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: As metamorphic testing generally requires the use of problem domain knowledge: the approach  is illustrated using several program examples4 Section B states the preliminaries and examples are  presented in Section N4 Concluding remarks are presented in Section O4    Preliminaries  Given a program  and a test case  : the corresponding output is denoted by  @  D4 Assume  is  P  x  P  x  x  a test case with output  @  D4 Our approach is to construct a number of new test cases  :  :  :  P  x  x  x  $ $ $  !\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In this paper, only the Erst type  of errors will be discussed0 A comprehensive treatment of the detection of other errors in numerical  problems using metamorphic testing can be found in GHI0  The idea for using metamorphic testing comes from the fact that if we prepare a new input pair  by interchanging any two rows of  and the corresponding entries of  , the output will be the same  A  b  as the output given the original input pair +  ,  -0\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: Published as Technical Report HKUST-CS98-01, Department of Computer Science  The Hong Kong University of Science and Technology, 1998.    Metamorphic Testing/  A New Approach for Generating Next Test Cases  y  Department of Computer Science3  The University of Melbourne  T!  Y!  Chen  Parkville =>?  @3 Australia  BtycCcs!mu!oz!auE  S!  C!  Cheung  x  Department of Computer Science3 The Hong Kong University of Science and Technology  Clear Water Bay3 Kowloon3 Hong Kong  BsccCcs!ust!hkE  S! M! Yiu  Department of Computer Science3\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: Calculate solution vector x6 78 EIFcG should be obtained 87   M! P    Conclusion  In this paper* we have proposed a new approach for generating test cases called  3  Metamorphic Testing  This approach aims at uncovering those errors which are commonly found in similar applications3  Test cases are generated according to the input8output pair of an 9apparently: successful test case*  which is selected using some well known criteria3 The test cases generated target those errors which  are possibly left undetected by the previous successful test case3 Metamorphic Testing enables soft8  ware practitioners to design additional tests and hence improve the software reliability3\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: It augments  the e>ectiveness of the existing testing strategies by making use of the corresponding successful test  cases to construct additional test cases3    In our approach* the design of next test cases  not depend on complicated theories3 Rather  need  it is based on programming experience and testing experience3 Examples are given to show that  this approach is feasible and that the newly constructed test cases are useful in revealing some  common errors3\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2613, 'completion_tokens': 162, 'total_tokens': 2775}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [5 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Limitations of Current Software Testing Techniques\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Traditionalsoftwaretestingtechniquesareconsideredtobeabletoprovidesystemdefectdetectionatanearlystage,whichispromisingtoenhancethesystemrobustness.  Testingisalsoawidely-usedtechniqueinhuntingbugsandevaluatingthequalityoftraditionalsoftwaresystems.\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: We call this approach  because new test cases are evolved from the old  Metamorphic Testing  ones that are normally selected according to some existing selection criteria including the random  selection strategy4  We wish to point out that metamorphic testing is to be used with other test case selection  strategies4 Based on each test case selected according to a speci/c strategy and its output result: a  number of new test cases can be designed to further test the software and increase our con/dence  in the software4  Furthermore: metamorphic testing can also be combined with Blum<s program  checker which stops after the veri/cation of the corresponding output is done but does not suggest  further testing4\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: Secondly, no matter how extensive the testing has  been conducted in the development phase, errors may still exist in the software >?  @4 These errors, if  left undetected, may eventually cause damage to the production system4  The study of techniques  for uncovering software errors in the production phase is seldom addressed in the literature4 Thirdly,  as indicated by Weyuker in >C@, the availability of test oracles is pragmatically unattainable in most  situations4 However, the availability of test oracles is generally assumed in conventional software  testing techniques4\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: It augments  the e>ectiveness of the existing testing strategies by making use of the corresponding successful test  cases to construct additional test cases3    In our approach* the design of next test cases  not depend on complicated theories3 Rather  need  it is based on programming experience and testing experience3 Examples are given to show that  this approach is feasible and that the newly constructed test cases are useful in revealing some  common errors3\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: As metamorphic testing requires problem domain knowledge in general8 we expect that a domain  speciAc methodology should be developed4 To facilitate the development of such a methodology8 we  are studying various criteria of classifying programs into their appropriate domains4  Acknowledgements  We would like to thank F4T4 Chan and M4F4 Lau for helpful discussion on the paper4 In particular8  example H is extracted and modiAed from an example in a manuscript by Chan8 Lau8 and the  authors44  References  IJK M4 Blum8 @Program Checking@8  Foundations of Software Technology and Theoretical Computer  Science  8 Lecture Notes in Computer Science8 Vol4\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: 5. CONCLUSION    The recent advances in test suite based program repair have made the once-futuristic idea of repairing programs automatically a achievable reality.  However, as tests suites are incomplete in nature, using test suites as correctness speciﬁcation makes test suite based repair techniques suf-  fer from the overﬁtting issue.  In this paper, we investigate the feasibility and eﬀectiveness of test case generation in alleviating the overﬁtting issue.  We have proposed two ap- proaches for using test case generation to improve test suite based repair techniques, and have conducted a large scale ex- periment to evaluate the proposed approaches.\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: Software Testing  Introduction  Although errors exist in most software systems8 they cannot be tolerated in general3  This is partic?    ularly the case if software systems are deployed for safety?critical applications3 Improving software  reliability has been a ma jor issue in software engineering3  is by far the most widely  Software Testing  used approach to examine the correctness of a piece of software before it is released for production3\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: The empirical study conducted by Martinez et al.  [22] reveals that among the 47 bugs ﬁxed by jGenProg, jKali, and Nopol, only 9 bugs are correctly ﬁxed, the rest being overﬁtting.    To improve test suite based repair techniques, we inves- tigate whether the overﬁtting problem can be alleviated by adding new test cases generated by an automatic test case generation tool.  We expect that the additional tests would make the correctness speciﬁcation more complete and thus help generate patches that are less likely to be oferﬁtting and more likely to be correct.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2666, 'completion_tokens': 211, 'total_tokens': 2877}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [6 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Proposed Test Case Selection Technique\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In this paper, we propose a novel test case selection technique that derives new  test cases from the successful ones4 The selection aims at revealing software errors that are possibly  left undetected in successful test cases which may be generated using some existing strategies4 As  such, the proposed technique augments the eFectiveness of existing test selection strategies4 The  y  This pro ject was partially supported by a grant from the Australian Research Council and the Hong Kong Research  Grant Council<  x    Corresponding Author  G  \f",
      "technique also helps uncover software errors in the production phase and can be used in the absence  of test oracles3    Keywords  4 Selection of Test Cases8 Software Quality8\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: This is particularly the case for applications in their  production phases3  It is therefore useful to have a technique which does not assume the availability  of such oracles3  In this paper8 a novel technique for test cases selection is proposed which constructs  new test cases from successful test cases8 aiming at revealing further software errors3  The technique  also helps uncover software errors in the production phase and can be used in the absence of test  oracles3  As our method is applicable to applications in both development and production phases8  for simplicity8 the inputs in the production phase will hereafter be referred to as test cases3 A test  case together with its test result will be referred to as an input?output pair3\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing8 a piece of software is tested against a set of test cases generated by a predeBned  test selection strategy3 A test case is  if it detects a software errorC otherwise it is  error-revealing  called  DEF3 Error?revealing test cases are generally regarded to be more informative than  successful  the successful ones as they demonstrate the existence of software errors3 Correction of such errors  improves the software reliability3    No matter how extensive testing has been conducted in the  during software de?  testing phase  velopment8 errors may still exist in a software system after it has been released for production DIF3\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: Secondly, no matter how extensive the testing has  been conducted in the development phase, errors may still exist in the software >?  @4 These errors, if  left undetected, may eventually cause damage to the production system4  The study of techniques  for uncovering software errors in the production phase is seldom addressed in the literature4 Thirdly,  as indicated by Weyuker in >C@, the availability of test oracles is pragmatically unattainable in most  situations4 However, the availability of test oracles is generally assumed in conventional software  testing techniques4\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: It augments  the e>ectiveness of the existing testing strategies by making use of the corresponding successful test  cases to construct additional test cases3    In our approach* the design of next test cases  not depend on complicated theories3 Rather  need  it is based on programming experience and testing experience3 Examples are given to show that  this approach is feasible and that the newly constructed test cases are useful in revealing some  common errors3\n",
      "\n",
      "\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: The approach is applicable in both the testing and production phases and does  not rely on the assumption of a test oracle3 We Cnd its application to the situations without test  DE            \f",
      "oracles particularly interesting as the problem is legitimate and has not been adequately addressed  by existing testing techniques4 Another advantage of the proposed approach is that it does not  depend on any particular test case selection strategy8 so it can be easily used along with other test  case selection strategies and can be easily combined with Blum;s program checker4    While the primary ob jective of this paper is to present the motivation of the approach and its  applicability8 a methodology supporting such an approach has yet been fully developed4\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Traditionalsoftwaretestingtechniquesareconsideredtobeabletoprovidesystemdefectdetectionatanearlystage,whichispromisingtoenhancethesystemrobustness.  Testingisalsoawidely-usedtechniqueinhuntingbugsandevaluatingthequalityoftraditionalsoftwaresystems.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the eﬀectiveness of the proposed approaches in enabling better test suite based re- pair on 224 bugs of the Defects4J repository.  The results indicate that test case generation can change the resulting patch, but is not eﬀective at turning incorrect patches into correct ones.  We identify the problems related with the inef- fectiveness, and anticipate that our results and ﬁndings will lead to future research to build test-case generation tech-  niques that are tailored to automatic repair systems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2718, 'completion_tokens': 178, 'total_tokens': 2896}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [7 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Codexglue for Machine Learning Research\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison.  CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform.  The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems 1.  KEYWORDS program understanding, machine learning, naturalness of software  1 INTRODUCTION Evans Data Corporation2 estimated that there were 23.9 million professional developers in 2019 and that the number was expected to reach 28.7 million in 2024.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation    [26] Daya Guo, Duyu Tang, Nan Duan, Ming Zhou, and Jian Yin. 2019.  Coupling Retrieval and Meta-Learning for Context-Dependent Semantic Parsing. arXiv preprint arXiv:1906.07108 (2019).    [27] Rahul Gupta, Aditya Kanade, and Shirish Shevade. 2019.  Neural Attribution for Se- mantic Bug-Localization in Student Programs.  In Advances in Neural Information Processing Systems.  11884–11894.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: With the growing demand for testing models’ generalization ability on a wide range of applications, researchers have created or assembled datasets that cover many tasks.  Rep- resentative samples of these datasets include ImageNet [15] for computer vision, GLUE  [81] for natural language understanding, XTREME  [33] and XGLUE  [48] for cross-lingual natural language processing.  To the best of our knowledge, CodeXGLUE is the first diversified benchmark dataset that can be applied to various code intelligence problems.    Many tasks related to machine learning for software engineer- ing\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Microsoft  Dawn Drain Microsoft  Ge Li  Peking University  Long Zhou  Microsoft Research Asia  Ming Zhou  Microsoft Research Asia  Shao Kun Deng Microsoft  Shujie Liu Microsoft Research Asia  Shuo Ren∗ Beihang University  Ambrosio Blanco Microsoft Research Asia  Daxin Jiang Microsoft  Lidong Zhou  Microsoft Research Asia  Michele Tufano Microsoft  Nan Duan Microsoft Research Asia  Shengyu Fu Microsoft  ABSTRACT Benchmark datasets have a significant impact on accelerating re- search in programming language tasks.  In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning re- search for program understanding and generation.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Table 1: A brief summary of CodeXGLUE, which includes tasks, datasets, languages, sizes in various states, and baseline sys- tems.  Highlighted datasets are newly introduced.    Lu, Guo, Ren and Huang, et al.  Category  Task  Clone Detection  Defect Detection  Cloze Test  Code Completion  Code Repair Code Translation  NL Code Search  Text-to-Code Generation  Code-Code  Text-Code  Dataset Name BigCloneBench  [71] POJ-104  [52] Devign [99]  CT-all  CT-max/min  [18]  PY150  [62] Github Java Corpus[4] Bugs2Fix\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: The pro- gram synthesis [20, 45, 53, 64, 68, 79, 98] extends the text-to-code generation task aims to generate programs from a specification [24], such as pseudocode, natural language description, and input/output examples.    7 CONCLUSION With CodeXGLUE, we seek to support the development of models that can be applied to various program understanding and gen- eration problems, with the goal of increasing the productivity of software developers.  We encourage researchers to participate in the open challenge to make progress in code intelligence.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Moving forward, we are planning to extend CodeXGLUE to more program- ming languages and downstream tasks while continuing to develop advanced pretrained models by exploring new model structures, introducing new pretraining tasks, using different types of data, and more.    REFERENCES [1] Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu, and Charles Sutton.  2018.  A Survey of Machine Learning for Big Code and Naturalness.  ACM Comput.  Surv.  51, 4, Article 81 (July 2018), 37 pages.  https://doi.org/10.1145/3212695\n",
      "\n",
      "\n",
      "Title: Leveraging automated unit tests for unsupervised code translation\n",
      "citation_id: 6\n",
      "Text: Codexglue:  A machine learning benchmark dataset for code understanding and generation.  arXiv preprint arXiv:2102.04664, 2021.    Antonio Valerio Miceli-Barone and Rico Sennrich.  A parallel corpus of python functions and docu- mentation strings for automated code documentation and code generation.  In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pp. 314–319, 2017.    12  \f",
      "Published as a conference paper at ICLR 2022  W. Miller and D. Spooner.  Automatic generation of ﬂoating-point test data.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 2 level markdown title (`##`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2708, 'completion_tokens': 104, 'total_tokens': 2812}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [8 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Background\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2521, 'completion_tokens': 140, 'total_tokens': 2661}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [9 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"CodeXGLUE\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison.  CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform.  The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems 1.  KEYWORDS program understanding, machine learning, naturalness of software  1 INTRODUCTION Evans Data Corporation2 estimated that there were 23.9 million professional developers in 2019 and that the number was expected to reach 28.7 million in 2024.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation    [26] Daya Guo, Duyu Tang, Nan Duan, Ming Zhou, and Jian Yin. 2019.  Coupling Retrieval and Meta-Learning for Context-Dependent Semantic Parsing. arXiv preprint arXiv:1906.07108 (2019).    [27] Rahul Gupta, Aditya Kanade, and Shirish Shevade. 2019.  Neural Attribution for Se- mantic Bug-Localization in Student Programs.  In Advances in Neural Information Processing Systems.  11884–11894.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: The pro- gram synthesis [20, 45, 53, 64, 68, 79, 98] extends the text-to-code generation task aims to generate programs from a specification [24], such as pseudocode, natural language description, and input/output examples.    7 CONCLUSION With CodeXGLUE, we seek to support the development of models that can be applied to various program understanding and gen- eration problems, with the goal of increasing the productivity of software developers.  We encourage researchers to participate in the open challenge to make progress in code intelligence.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Table 1: A brief summary of CodeXGLUE, which includes tasks, datasets, languages, sizes in various states, and baseline sys- tems.  Highlighted datasets are newly introduced.    Lu, Guo, Ren and Huang, et al.  Category  Task  Clone Detection  Defect Detection  Cloze Test  Code Completion  Code Repair Code Translation  NL Code Search  Text-to-Code Generation  Code-Code  Text-Code  Dataset Name BigCloneBench  [71] POJ-104  [52] Devign [99]  CT-all  CT-max/min  [18]  PY150  [62] Github Java Corpus[4] Bugs2Fix\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: With the growing demand for testing models’ generalization ability on a wide range of applications, researchers have created or assembled datasets that cover many tasks.  Rep- resentative samples of these datasets include ImageNet [15] for computer vision, GLUE  [81] for natural language understanding, XTREME  [33] and XGLUE  [48] for cross-lingual natural language processing.  To the best of our knowledge, CodeXGLUE is the first diversified benchmark dataset that can be applied to various code intelligence problems.    Many tasks related to machine learning for software engineer- ing\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Moving forward, we are planning to extend CodeXGLUE to more program- ming languages and downstream tasks while continuing to develop advanced pretrained models by exploring new model structures, introducing new pretraining tasks, using different types of data, and more.    REFERENCES [1] Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu, and Charles Sutton.  2018.  A Survey of Machine Learning for Big Code and Naturalness.  ACM Comput.  Surv.  51, 4, Article 81 (July 2018), 37 pages.  https://doi.org/10.1145/3212695\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Microsoft  Dawn Drain Microsoft  Ge Li  Peking University  Long Zhou  Microsoft Research Asia  Ming Zhou  Microsoft Research Asia  Shao Kun Deng Microsoft  Shujie Liu Microsoft Research Asia  Shuo Ren∗ Beihang University  Ambrosio Blanco Microsoft Research Asia  Daxin Jiang Microsoft  Lidong Zhou  Microsoft Research Asia  Michele Tufano Microsoft  Nan Duan Microsoft Research Asia  Shengyu Fu Microsoft  ABSTRACT Benchmark datasets have a significant impact on accelerating re- search in programming language tasks.  In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning re- search for program understanding and generation.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: CodeXGLUE sup- ports the following tasks:  • code-code (clone detection  [10, 52, 71, 84, 89, 93, 97], defect detection  [47, 57, 61, 82, 83, 99], cloze test [18], code comple- tion [4, 8, 9, 31, 62, 63, 72, 73], code repair  [2, 28, 30, 75, 76, 78], and code-to-code translation\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2665, 'completion_tokens': 163, 'total_tokens': 2828}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [10 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Impact of Benchmark Datasets on Accelerating Research\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: 2https://evansdata.com/press/viewRelease.php?pressID=278  It is commonly accepted that benchmarks have a significant impact on the growth of applied AI research.  In this paper, we focus on establishing a benchmark dataset for code intelligence.    Automated program understanding and generation could in- crease the productivity of software developers.  In fact, developers who want to find code written by others with the same intent can leverage code search systems  [23, 35, 58, 85] to automatically re- trieve semantically relevant codes through natural language queries.  Similarly, developers who are confused about what to write next can use code completion systems\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Microsoft  Dawn Drain Microsoft  Ge Li  Peking University  Long Zhou  Microsoft Research Asia  Ming Zhou  Microsoft Research Asia  Shao Kun Deng Microsoft  Shujie Liu Microsoft Research Asia  Shuo Ren∗ Beihang University  Ambrosio Blanco Microsoft Research Asia  Daxin Jiang Microsoft  Lidong Zhou  Microsoft Research Asia  Michele Tufano Microsoft  Nan Duan Microsoft Research Asia  Shengyu Fu Microsoft  ABSTRACT Benchmark datasets have a significant impact on accelerating re- search in programming language tasks.  In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning re- search for program understanding and generation.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Figure 8 shows how long it takes to train the model and to do inference on the model, as well as in other tasks.    6 RELATED WORK Benchmark datasets have been playing a central role in the growth of applied AI research.  For example, the LibriSpeech [55] and the SQuAD  [60] datasets drive the development of data-driven models for automatic speech recognition and reading comprehension of  \f",
      "CodeXGLUE:  A Machine Learning Benchmark Dataset for Code Understanding and Generation  Table 11: Results on the code repair task.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Very recently, the application of pretrained models that learn from big programming language data has been inspired by the great success of pretrained models like BERT [16] and GPT  [69] in natural lan- guage processing (NLP).  These models, including CodeBERT [18] and IntelliCode Compose [72], have led to further improvements in code understanding and generation problems, but they lack a benchmark suite that covers a wide range of tasks.  The use of Ima- geNet [15] for computer vision and the use of GLUE  [81] for NLP have shown that a diversified benchmark dataset has a significant impact on the growth of applied AI research.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: [52], Devign [99], PY150  [62], Github Java Corpus [4], Bugs2Fix [75], CONCODE [38], and  CodeSearch- Net  [35]— but also newly introduced datasets that are highlighted in Table 1.  The datasets are chosen or created based on the considera- tion that the task has clear definition, and the volume of the dataset could support the development and evaluation of data-driven ma- chine learning methods.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: The datasets created by us include (1) two cloze test test sets that cover 6 programming languages, (2) two line- level code completion test sets in Java and Python, respectively, (3) a code-to-code translation dataset between Java and C#, (4) two natu- ral language code search test sets with web queries and normalized function and variable names, respectively, and (5) a documentation translation dataset that covers five natural languages.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: With the growing demand for testing models’ generalization ability on a wide range of applications, researchers have created or assembled datasets that cover many tasks.  Rep- resentative samples of these datasets include ImageNet [15] for computer vision, GLUE  [81] for natural language understanding, XTREME  [33] and XGLUE  [48] for cross-lingual natural language processing.  To the best of our knowledge, CodeXGLUE is the first diversified benchmark dataset that can be applied to various code intelligence problems.    Many tasks related to machine learning for software engineer- ing\n",
      "\n",
      "\n",
      "Title: Codebert: A pre-trained model for programming and natural languages\n",
      "citation_id: 8\n",
      "Text: Accuracies (%) are reported.  Best results in each group are in bold.    datasets in different programming languages are extremely unbalanced, we report the accumulated metric with the same way.  We use CodeBERT (MLM) here because its output layer naturally ﬁts for probing.  Results show that CodeBERT per- forms better than baselines on almost all languages on both NL and PL probing.  The numbers with only preceding contexts are lower than that with bidirectional contexts, which suggests that code completion is challenging.  We leave it as a future work.    We further give a case study on PL-NL probing.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2570, 'completion_tokens': 102, 'total_tokens': 2672}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [11 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Neuro-Symbolic Program Synthesis\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: While achieving impressive results, these approaches have a number of important limi- tations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is deﬁned by a neural network).  In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems.  Once trained, our approach can au- tomatically construct computer programs in a domain-speciﬁc language that are consistent with a set of input-output examples provided at test time.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: These techniques not only require signiﬁcant engineering and research effort to develop carefully-designed heuristics for efﬁcient search, but also have limited applicability and can only synthesize programs of limited sizes and types.    In this paper, we present a novel technique called Neuro-Symbolic Program Synthesis (NSPS) that learns to generate a program incrementally without the need for an explicit search.  Once trained, NSPS can automatically construct computer programs that are consistent with any set of input-output examples provided at test time.  Our method is based on two novel module neural architectures.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: A novel Neuro-Symbolic program synthesis technique to encode neural search over the  space of programs deﬁned using a Domain-Speciﬁc Language (DSL).    •  The R3NN model that encodes and expands partial programs in the DSL, where each node  has a global representation of the program tree.    •  A novel cross-correlation based neural architecture for learning continuous representation  of sets of input-output examples.    • Evaluation of the NSPS approach on the complex domain of regular expression based string  transformations.    2 PROBLEM DEFINITION  In this section, we formally deﬁne the DSL-based program synthesis problem that we consider in this paper.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Motivated by the need for model interpretability and scalability to multiple tasks, we address the problem of Program Synthesis.  Program Synthesis, the problem of automatically constructing pro- grams that are consistent with a given speciﬁcation, has long been a subject of research in Computer Science (Biermann, 1978; Summers, 1977).\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: The Inside-Outside Recursive Neural Network (Le & Zuidema, 2014) in particular is most similar to the R3NN, where they generate a parse tree incrementally by using global leaf-level representations to determine which expansions in the parse tree to take next.    8 CONCLUSION  We have proposed a novel technique called Neuro-Symbolic Program Synthesis that is able to con- struct a program incrementally based on given input-output examples.  To do so, a new neural architecture called Recursive-Reverse-Recursive Neural Network is used to encode and expand a partial program tree into a full program tree.  Its effectiveness at example-based program synthesis is demonstrated, even when the program has not been seen during training.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: 1Microsoft Research, USA 2Carnegie Mellon University, USA eparisot@andrew.cmu.edu , {asamir,risin,lihongli,denzho,pkohli}@microsoft.com  ABSTRACT    Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction.  Given a set of input-output examples, these ar- chitectures are able to learn mappings that generalize to new test inputs.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Liang et al. (2010) restrict the problem space with a probabilistic context-free grammar and introduce a new representation of programs based on combinatory logic, which allows for sharing sub-programs across multiple tasks.  They then take a hierarchical Bayesian approach to learn frequently occurring substructures of programs.  Our approach, instead, uses neural architectures to condition the search space of pro- grams, and does not require additional step of representing program space using combinatory logic for allowing sharing.    The DSL-based program synthesis approach has also seen a renewed interest recently (Alur et al., 2015).\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: However, unlike our approach that learns comprehensible complete programs, many of these ap- proaches learn only the program behavior (i.e., they produce desired outputs on new input data).  Some recently proposed methods (Kurach et al., 2015; Gaunt et al., 2016; Riedel et al., 2016; Bunel et al., 2016) do learn interpretable programs but these techniques require learning a separate neural network model for each individual task, which is undesirable in many synthesis settings where we would like to learn programs in real-time for a large number of tasks.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 2 level markdown title (`##`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2708, 'completion_tokens': 181, 'total_tokens': 2889}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [12 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Background\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2520, 'completion_tokens': 168, 'total_tokens': 2688}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [13 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Neuro-Symbolic Program Synthesis\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: While achieving impressive results, these approaches have a number of important limi- tations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is deﬁned by a neural network).  In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems.  Once trained, our approach can au- tomatically construct computer programs in a domain-speciﬁc language that are consistent with a set of input-output examples provided at test time.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: These techniques not only require signiﬁcant engineering and research effort to develop carefully-designed heuristics for efﬁcient search, but also have limited applicability and can only synthesize programs of limited sizes and types.    In this paper, we present a novel technique called Neuro-Symbolic Program Synthesis (NSPS) that learns to generate a program incrementally without the need for an explicit search.  Once trained, NSPS can automatically construct computer programs that are consistent with any set of input-output examples provided at test time.  Our method is based on two novel module neural architectures.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: A novel Neuro-Symbolic program synthesis technique to encode neural search over the  space of programs deﬁned using a Domain-Speciﬁc Language (DSL).    •  The R3NN model that encodes and expands partial programs in the DSL, where each node  has a global representation of the program tree.    •  A novel cross-correlation based neural architecture for learning continuous representation  of sets of input-output examples.    • Evaluation of the NSPS approach on the complex domain of regular expression based string  transformations.    2 PROBLEM DEFINITION  In this section, we formally deﬁne the DSL-based program synthesis problem that we consider in this paper.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: The Inside-Outside Recursive Neural Network (Le & Zuidema, 2014) in particular is most similar to the R3NN, where they generate a parse tree incrementally by using global leaf-level representations to determine which expansions in the parse tree to take next.    8 CONCLUSION  We have proposed a novel technique called Neuro-Symbolic Program Synthesis that is able to con- struct a program incrementally based on given input-output examples.  To do so, a new neural architecture called Recursive-Reverse-Recursive Neural Network is used to encode and expand a partial program tree into a full program tree.  Its effectiveness at example-based program synthesis is demonstrated, even when the program has not been seen during training.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Motivated by the need for model interpretability and scalability to multiple tasks, we address the problem of Program Synthesis.  Program Synthesis, the problem of automatically constructing pro- grams that are consistent with a given speciﬁcation, has long been a subject of research in Computer Science (Biermann, 1978; Summers, 1977).\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Liang et al. (2010) restrict the problem space with a probabilistic context-free grammar and introduce a new representation of programs based on combinatory logic, which allows for sharing sub-programs across multiple tasks.  They then take a hierarchical Bayesian approach to learn frequently occurring substructures of programs.  Our approach, instead, uses neural architectures to condition the search space of pro- grams, and does not require additional step of representing program space using combinatory logic for allowing sharing.    The DSL-based program synthesis approach has also seen a renewed interest recently (Alur et al., 2015).\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: 1Microsoft Research, USA 2Carnegie Mellon University, USA eparisot@andrew.cmu.edu , {asamir,risin,lihongli,denzho,pkohli}@microsoft.com  ABSTRACT    Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction.  Given a set of input-output examples, these ar- chitectures are able to learn mappings that generalize to new test inputs.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: However, unlike our approach that learns comprehensible complete programs, many of these ap- proaches learn only the program behavior (i.e., they produce desired outputs on new input data).  Some recently proposed methods (Kurach et al., 2015; Gaunt et al., 2016; Riedel et al., 2016; Bunel et al., 2016) do learn interpretable programs but these techniques require learning a separate neural network model for each individual task, which is undesirable in many synthesis settings where we would like to learn programs in real-time for a large number of tasks.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2677, 'completion_tokens': 240, 'total_tokens': 2917}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [14 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server is currently overloaded with other requests. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Automatically Constructing Computer Programs\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: While achieving impressive results, these approaches have a number of important limi- tations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is deﬁned by a neural network).  In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems.  Once trained, our approach can au- tomatically construct computer programs in a domain-speciﬁc language that are consistent with a set of input-output examples provided at test time.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Given a DSL L, we learn a generative model of pro- grams in the DSL L that is conditioned on input-output examples to efﬁciently search for consistent programs.  The workﬂow of our system is shown in Figure 2, which is trained end-to-end using a large training set of programs in the DSL together with their corresponding input-output examples.  To generate a large training set, we uniformly sample programs from the DSL and then use a rule- based strategy to compute well-formed input strings that satisfy the pre-conditions of the programs.  The corresponding output strings are obtained by running the programs on the input strings.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Motivated by the need for model interpretability and scalability to multiple tasks, we address the problem of Program Synthesis.  Program Synthesis, the problem of automatically constructing pro- grams that are consistent with a given speciﬁcation, has long been a subject of research in Computer Science (Biermann, 1978; Summers, 1977).\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: The proposed two approaches target generate-and-validate and synthesis-based techniques respectively.    3.1 Analysis of the Problem  3.1.1  Input domain  Let us reason about the input space I of a program P .  We consider modern and object-oriented programs, where an input point is composed of one or more objects, interact- ing through a sequence of methods calls.  In a typical repair scenario, the program is almost correct and thus a bug only aﬀects the behaviors of a portion of the input domain, which we call the buggy input domain Ibug.  We call the rest of the input domain, for which the program behaviors are con- sidered as correct Icorrect.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: The synthesis techniques proposed in the literature generally employ various search techniques in- cluding enumeration with pruning, symbolic constraint solving, and stochastic search, while sup- porting different forms of speciﬁcations including input-output examples, partial programs, program invariants, and reference implementation.    In this paper, we consider input-output example based speciﬁcation over the hypothesis space de- ﬁned by a DSL of string transformations, similar to that of FlashFill (without conditionals) (Gul- wani, 2011).\n",
      "\n",
      "\n",
      "Title: Codet: Code generation with generated tests\n",
      "citation_id: 10\n",
      "Text: Automatic Test Case Generation Automated test case generation for programming problems can reduce the effort of writing test cases manually by developers.  Early works including Ran- doop (Pacheco et al., 2007), EvoSuite (Fraser & Arcuri, 2011), MOSA (Panichella et al., 2015), DynaMOSA (Panichella et al., 2017), and MIO (Arcuri, 2017), were proposed to automatically generate test cases for statically typed programming languages like Java.  The later proposed Pyn- guin (Lukasczyk & Fraser, 2022) could handle dynamically typed language like Python.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: This interest has been reinvigorated in recent years on  1              \f",
      "Under review as a conference paper at ICLR 2017  the back of the development of methods for learning programs in various domains, ranging from low-level bit manipulation code (Solar-Lezama et al., 2005) to data structure manipulations (Singh & Solar-Lezama, 2011) and regular expression based string transformations (Gulwani, 2011).    Most of the recently proposed methods for program synthesis operate by searching the space of programs in a Domain-Speciﬁc Language (DSL) instead of arbitrary Turing-complete languages.\n",
      "\n",
      "\n",
      "Title: Codet: Code generation with generated tests\n",
      "citation_id: 10\n",
      "Text: ABSTRACT    The task of generating code solutions for a given programming problem can bene- ﬁt from the use of pre-trained language models such as Codex, which can produce multiple diverse samples.  However, a major challenge for this task is to select the most appropriate solution from the multiple samples generated by the pre- trained language models.  A natural way to evaluate the quality and correctness of a code solution is to run it against a set of test cases, but the manual creation of such test cases is often costly and time-consuming.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2706, 'completion_tokens': 183, 'total_tokens': 2889}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [15 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Test Case Generation for Program Repair\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: 5. CONCLUSION    The recent advances in test suite based program repair have made the once-futuristic idea of repairing programs automatically a achievable reality.  However, as tests suites are incomplete in nature, using test suites as correctness speciﬁcation makes test suite based repair techniques suf-  fer from the overﬁtting issue.  In this paper, we investigate the feasibility and eﬀectiveness of test case generation in alleviating the overﬁtting issue.  We have proposed two ap- proaches for using test case generation to improve test suite based repair techniques, and have conducted a large scale ex- periment to evaluate the proposed approaches.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Test-suites are in essence input-output speciﬁcations and are therefore typically inadequate for com- pletely specifying the expected behavior of the program un- der repair.  Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect.  Patches that are overly speciﬁc to the used test suite and fail to generalize to other test cases are called overﬁtting patches.  In this paper, we investigate the feasi- bility and eﬀectiveness of test case generation in alleviating the overﬁtting issue.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: It uses an evolutionary approach  2  \f",
      "to derive test suites that maximize code coverage, and gen- erates assertions that encode the current behavior of the program.  To our knowledge, no signiﬁcant work has been published on the use of test case generation for program repair.    3. APPROACH  In this section, we present two approaches for improving test suite based repair with test case generation.  Given a test suite based repair technique and the initial manually written test suite, our aim is to use additional automatically gener- ated tests to guide the patch generation process towards generating patches that are less likely to be overﬁtting.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Test Case Generation for Program Repair: A Study of Feasibility and Effectiveness  Zhongxing Yu, Matias Martinez, Benjamin Danglot, Thomas Durieux and Martin Monperrus  7 1 0 2  r a  M 1  ] E S .  s c  [  1 v 8 9 1 0 0 .  3 0 7 1 :  v i X r a  ABSTRACT Among the many diﬀerent kinds of program repair tech-  niques, one widely studied family of techniques is called test suite based repair.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: An analysis of the use of generated test cases in the context of automated program repair, and a charac- terization of the overﬁtting problem.    • Two approaches for using test case generation in test suite based repair.  The ﬁrst one works with generate- and-validate techniques (MinImpact) and the second one for synthesis-based techniques (UnsatGuided).    • An extensive evaluation of the eﬀectiveness of the pro- posed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the eﬀectiveness of the proposed approaches in enabling better test suite based re- pair on 224 bugs of the Defects4J repository.  The results indicate that test case generation can change the resulting patch, but is not eﬀective at turning incorrect patches into correct ones.  We identify the problems related with the inef- fectiveness, and anticipate that our results and ﬁndings will lead to future research to build test-case generation tech-  niques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: To the best of our knowledge, this paper is the ﬁrst system- atic and large-scale investigation of the feasibility and eﬀectiveness of test generation for repair.    The remainder of this paper is structured as follows.  We ﬁrst present related work in Section 2.  Section 3 describes the proposed approaches.  Section 4 presents and discusses experimental results, followed by Section 5 which concludes this paper.    2.  RELATED WORK  2.1 Test Suite Based Program Repair  Generate-and-validate repair techniques ﬁrst search within a search space to generate a set of patches, and then validate the generated patches against the test suite.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 2 level markdown title (`##`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2607, 'completion_tokens': 203, 'total_tokens': 2810}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [16 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Background\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Background: This subsection provides a brief history of program repair techniques and their limitations.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2518, 'completion_tokens': 159, 'total_tokens': 2677}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [17 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Feasibility and Effectiveness of Test Case Generation\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: 5. CONCLUSION    The recent advances in test suite based program repair have made the once-futuristic idea of repairing programs automatically a achievable reality.  However, as tests suites are incomplete in nature, using test suites as correctness speciﬁcation makes test suite based repair techniques suf-  fer from the overﬁtting issue.  In this paper, we investigate the feasibility and eﬀectiveness of test case generation in alleviating the overﬁtting issue.  We have proposed two ap- proaches for using test case generation to improve test suite based repair techniques, and have conducted a large scale ex- periment to evaluate the proposed approaches.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Test-suites are in essence input-output speciﬁcations and are therefore typically inadequate for com- pletely specifying the expected behavior of the program un- der repair.  Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect.  Patches that are overly speciﬁc to the used test suite and fail to generalize to other test cases are called overﬁtting patches.  In this paper, we investigate the feasi- bility and eﬀectiveness of test case generation in alleviating the overﬁtting issue.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: The patches that are overly speciﬁc to the used test suite and fail to generalize to other test cases are called overﬁtting patches.  Overﬁtting is, indeed, a serious issue associated with test suite based repair techniques and some recent studies have shown that a signiﬁcant portion of the patches generated by test suite based repair techniques are just overﬁtting patches  [39, 35, 22].  Can test-case generation help in avoiding overﬁtting?    In this paper, we investigate the feasibility and eﬀective-  ness of test case generation in alleviating the overﬁtting is- sue.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Test Case Generation for Program Repair: A Study of Feasibility and Effectiveness  Zhongxing Yu, Matias Martinez, Benjamin Danglot, Thomas Durieux and Martin Monperrus  7 1 0 2  r a  M 1  ] E S .  s c  [  1 v 8 9 1 0 0 .  3 0 7 1 :  v i X r a  ABSTRACT Among the many diﬀerent kinds of program repair tech-  niques, one widely studied family of techniques is called test suite based repair.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: To the best of our knowledge, this paper is the ﬁrst system- atic and large-scale investigation of the feasibility and eﬀectiveness of test generation for repair.    The remainder of this paper is structured as follows.  We ﬁrst present related work in Section 2.  Section 3 describes the proposed approaches.  Section 4 presents and discusses experimental results, followed by Section 5 which concludes this paper.    2.  RELATED WORK  2.1 Test Suite Based Program Repair  Generate-and-validate repair techniques ﬁrst search within a search space to generate a set of patches, and then validate the generated patches against the test suite.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the eﬀectiveness of the proposed approaches in enabling better test suite based re- pair on 224 bugs of the Defects4J repository.  The results indicate that test case generation can change the resulting patch, but is not eﬀective at turning incorrect patches into correct ones.  We identify the problems related with the inef- fectiveness, and anticipate that our results and ﬁndings will lead to future research to build test-case generation tech-  niques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: An analysis of the use of generated test cases in the context of automated program repair, and a charac- terization of the overﬁtting problem.    • Two approaches for using test case generation in test suite based repair.  The ﬁrst one works with generate- and-validate techniques (MinImpact) and the second one for synthesis-based techniques (UnsatGuided).    • An extensive evaluation of the eﬀectiveness of the pro- posed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2606, 'completion_tokens': 178, 'total_tokens': 2784}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [18 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Proposed Approaches for Using Test Case Generation\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: It uses an evolutionary approach  2  \f",
      "to derive test suites that maximize code coverage, and gen- erates assertions that encode the current behavior of the program.  To our knowledge, no signiﬁcant work has been published on the use of test case generation for program repair.    3. APPROACH  In this section, we present two approaches for improving test suite based repair with test case generation.  Given a test suite based repair technique and the initial manually written test suite, our aim is to use additional automatically gener- ated tests to guide the patch generation process towards generating patches that are less likely to be overﬁtting.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the eﬀectiveness of the proposed approaches in enabling better test suite based re- pair on 224 bugs of the Defects4J repository.  The results indicate that test case generation can change the resulting patch, but is not eﬀective at turning incorrect patches into correct ones.  We identify the problems related with the inef- fectiveness, and anticipate that our results and ﬁndings will lead to future research to build test-case generation tech-  niques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: 5. CONCLUSION    The recent advances in test suite based program repair have made the once-futuristic idea of repairing programs automatically a achievable reality.  However, as tests suites are incomplete in nature, using test suites as correctness speciﬁcation makes test suite based repair techniques suf-  fer from the overﬁtting issue.  In this paper, we investigate the feasibility and eﬀectiveness of test case generation in alleviating the overﬁtting issue.  We have proposed two ap- proaches for using test case generation to improve test suite based repair techniques, and have conducted a large scale ex- periment to evaluate the proposed approaches.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: An analysis of the use of generated test cases in the context of automated program repair, and a charac- terization of the overﬁtting problem.    • Two approaches for using test case generation in test suite based repair.  The ﬁrst one works with generate- and-validate techniques (MinImpact) and the second one for synthesis-based techniques (UnsatGuided).    • An extensive evaluation of the eﬀectiveness of the pro- posed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: To the best of our knowledge, this paper is the ﬁrst system- atic and large-scale investigation of the feasibility and eﬀectiveness of test generation for repair.    The remainder of this paper is structured as follows.  We ﬁrst present related work in Section 2.  Section 3 describes the proposed approaches.  Section 4 presents and discusses experimental results, followed by Section 5 which concludes this paper.    2.  RELATED WORK  2.1 Test Suite Based Program Repair  Generate-and-validate repair techniques ﬁrst search within a search space to generate a set of patches, and then validate the generated patches against the test suite.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Test suite based repair starts with some passing tests as the speciﬁcation of the expected behavior of the program and at least one failing test as a speciﬁcation of the bug to be repaired, and aims at generating patches that make all the test cases pass.  Based on the used patch generation strat- egy, test suite based repair can further be informally divided into two general categories, including generate-and-validate techniques and synthesis-based techniques.  Generate-and- validate techniques ﬁrst use certain methods such as genetic programming to generate a set of patches, and then validate the generated patches against the test suite.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: By generating tests using the version-to-be-repaired as an oracle, we obtain tests that would detect errors when the generated patches break some existing functionality.  The question then arises is how to make best use of the auto- matically generated test cases.  As we have said, the two categories of tests-suite based repair techniques make use of the tests very diﬀerently.  By leveraging the speciﬁcity of each technique, we design and present two approaches for ap- propriately using generated tests in the context of program repair: approach MinImpact is appropriate for generate- and-validate techniques that can enumerate patches and ap-\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2582, 'completion_tokens': 288, 'total_tokens': 2870}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [19 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Combinatorial Testing for Deep Learning Systems\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: CombinatorialTestingforDeepLearningSystems3–WealsoprovideageneralCTcoverageguidedtestgenerationtechniqueforDLsystems.–WeperformextensiveempiricalstudiesusinglinearprogrammingbasedtestgenerationtodemonstratetheusefulnessoftheproposedDLtestingtech-niques.  WehighlightthatCTcanprovideapromisingavenuefortestingDLsystems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Keywords:Combinatorialtesting·Deeplearning·Adversarialattacks1IntroductionDeeplearning(DL)systemshavebeenwidelyappliedinvariousapplicationsduetotheirhighaccuracy,suchascomputervision[35],naturallanguageprocess-ing[39],autonomousdriving[5],andautomatedmedicaldiagnosis[33].However,recentlyDLsystemshavebeenshowntobevulnerableagainstdiﬀerentattacks,suchasadversarialexamplesincomputervisionandaudiosystems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: In:InternationalConferenceonComputerAidedVeriﬁcation.pp.3–29(2017)\f",
      "CombinatorialTestingforDeepLearningSystems1316.IBM:IBMCPLEXmathematicalprogrammingsolverforlinearprogramming.https://www.ibm.com/analytics/cplex-optimizer17.Jia,Y.,Cohen,M.B.,Harman,M.,Petke,J.:Learningcombinatorialinteractiontestgenerationstrategiesusinghyperheuristicsearch.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: DeepCTenablestheguidedtestgenerationtoachievehighCTcoverageandallowstodetectlocal-robustnessissuesevenonlytheﬁrstseverallayersofaDNNareanalyzed.5.3DiscussionInthispaper,wedemonstratetheusefulnessofcombinatorialtestingforDNNs,andwebelieveCTwouldbeanimportantandpromisingdirectionfortestingDNNs.  However,manyopenquestionsneedfurtherinvestigationtowardsthepracticalapplicationofCTtoreal-worldlarge-scaleDLsystems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: InourstudiedDNNs,CT-guidedtestgenerationthatsystematicallycoverstheCTcoveragetargetsfortheﬁrstseverallayersofDNNsalreadyenablestodetectsuﬃcientadversarialexamplesandlocal-robustnessissues;wewillinvestigatewhetherthisresultscouldgeneralizetootherdatasetandDNNsinourfuturework.  Ourproposedcombinatorialtestingcoveragecriteriaareusefulforadver-sarialexampledetectionandlocal-robustnessanalysis.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Asmentionedinthelastsection,DeepCTproposesageneralcombinatorialcoverageguidedtestingmethodforDNNs,thetestgenerationtechniquecouldbesubstitutedbyothertechniquesaswell.  Thepurposeofthisworkthatadoptsaconstraint-basedapproachistodemonstratetheusefulnessoftheproposedCTcoveragecriteriafortestingDNNs.  However,weﬁndthatthenumberofneuronsisoftenquitelargeinpracticalDLsystems,anditwouldgreatlyhindertheconstraint-basedtestgenerationtechniques.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: 6 0 8 1 :  v i X r a  CombinatorialTestingforDeepLearningSystemsLeiMa1,2,FuyuanZhang2,MinhuiXue3,BoLi4,YangLiu2,JianjunZhao5,andYadongWang11HarbinInstituteofTechnology,China2NanyangTechnologicalUniversity,Singapore3NewYorkUniversityShanghai,China4UniversityofIllinoisatUrbana–Champaign,USA5KyushuUniversity,JapanContactauthor:malei@hit.edu.cnAbstract.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: WeshowthatgeneratingsuﬃcienttestsetofreasonablesizeandtesteﬀectivenesscanbeachievedinparallelbyleveragingCT,whichhasnotbeenexaminedpreviously.3CombinatorialTestingCriteriaforDLWeuseN={n1,n2,...}torepresentthesetofneuronsofaDLsystem,andT={x1,x2,...}thesetoftestinputs.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: WeadapttheconceptinCTandproposeasetofcoveragecriteriaforDLsystems,aswellasaCTcoverageguidedtestgenerationtechnique.OurevaluationdemonstratesthatCTprovidesapromisingavenuefortestingDLsystems.  WefurtherposeseveralopenquestionsandinterestingdirectionsforcombinatorialtestingofDLsys-tems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 2 level markdown title (`##`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eabdf0a8e052136d8bd5d388850365a3 in your message.).\n",
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2597, 'completion_tokens': 186, 'total_tokens': 2783}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [20 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Background\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2520, 'completion_tokens': 125, 'total_tokens': 2645}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [21 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Combinatorial Testing\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Manyadvancedcombinatorialtestgenerationstrategiescouldbefurtherexplored,whichcouldpotentiallyobtainhighCTcoveragewithevenlesstests[10,13,17,22,27,40].WewillalsostudydiversemoreoptimizedCTstrategiesinthenextstep.6ConclusionCombinatorialtestingisawell-establishedandsuccessfultechniqueintraditionalsoftwaretesting.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Ratherthanexhaustivelysearchingallthecombinationsofinputspace,CTfocusesontestingtheinteractionsofinputs,aimingtoreducethetestsizewhileobtainingsatisﬁabledefectdetectionabilities.ThispaperinitiatesanempiricalstudyontheusefulnessofCTfortestingDLsystems.OurevaluationresultsdemosratethatCTprovidesapromisingavenuefortestingDLsystems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Tothebestofourknowledge,thisistheﬁrstworktoexplorethefeasibilityandusefulnessofCTonDLsystems.2RelatedWorkInthissection,wewillreviewbasiccombinatorialtesting(CT)techniques,aswellaspointoutthechallengesofdirectlyapplyingCTtoDLsystems.2.1CombinatorialTestingEnsuringthequalityandcorrectnessofasystemischallengingduetovariousconﬁgurationsandinputdomainsforeachprogram.  Usually,totestasystemdemandsexhaustiveevaluationofallpossibleconﬁgurationsandinputinterac-tionsagainsttheirexpectedoutputs.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: However,randomtestingoftencouldbeineﬀectiveatdetectingadversarialex-amplesevenifalargenumberoftestsaregenerated[34].Tosystematicallygenerateteststodetectadversarialexamplesandanalyzethelocalrobustnessofagiveninput,weproposetoadaptcombinatorialtestingfortestsuitegener-ation.Algorithm1showsthedetailsofourCTcoverageguidedtestgeneration.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: However,suchanexhaustivetestingeﬀortisinfeasibleconsideringtheruntimeandcomputationresourcelimitations.  Thus,samplingmechanismsareappliedtoreducethedimensionoftestinput,whichwecallblack-boxsamplingbasedcombinatorialtesting(CT).CThasbeensuccess-fullyappliedtotestingdiﬀerentconﬁgurablesoftwaresystems[2,23,28],sincemostfaultsarecausedbyinteractionsinvolvingonlyafewparameters[20].De-spitethehightestingeﬃciency,CTislimitedinhandlingvariousconstraints.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: ,massiveruntimestates)stillremainunknown,whichisimportanttotherobustnessevaluationofDLsystems.  Therefore,weaimtoeﬃcientlytestlarge-scaleDLsystemsbasedonreasonablesizeofrepresentativetestinputs.  Combinatorialtesting(CT),whichisusedtosampletestinputsandconﬁg-urationsfromtheoriginalspace,canwelltrade-oﬀthedefectdetectionabilityandthesizeoftestinput.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Themainchallengeoftestingsuchsystemsisthatitsruntimestatespaceistoolarge:ifwevieweachneuronasaruntimestateforDL,thenaDLsystemoftencontainsmassivestates,renderingtestingeachstatealmostimpossible.  Fortraditionalsoftware,combinatorialtesting(CT)isaneﬀectivetest-ingtechniquetoreducethetestingspacewhileobtainingrelativelyhighdefectdetectionabilities.  Inthispaper,weperformanexploratorystudyofCTonDLsystems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: WeshowthatgeneratingsuﬃcienttestsetofreasonablesizeandtesteﬀectivenesscanbeachievedinparallelbyleveragingCT,whichhasnotbeenexaminedpreviously.3CombinatorialTestingCriteriaforDLWeuseN={n1,n2,...}torepresentthesetofneuronsofaDLsystem,andT={x1,x2,...}thesetoftestinputs.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: CombinatorialTestingforDeepLearningSystems3–WealsoprovideageneralCTcoverageguidedtestgenerationtechniqueforDLsystems.–WeperformextensiveempiricalstudiesusinglinearprogrammingbasedtestgenerationtodemonstratetheusefulnessoftheproposedDLtestingtech-niques.  WehighlightthatCTcanprovideapromisingavenuefortestingDLsystems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: DeepCTenablestheguidedtestgenerationtoachievehighCTcoverageandallowstodetectlocal-robustnessissuesevenonlytheﬁrstseverallayersofaDNNareanalyzed.5.3DiscussionInthispaper,wedemonstratetheusefulnessofcombinatorialtestingforDNNs,andwebelieveCTwouldbeanimportantandpromisingdirectionfortestingDNNs.  However,manyopenquestionsneedfurtherinvestigationtowardsthepracticalapplicationofCTtoreal-worldlarge-scaleDLsystems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2718, 'completion_tokens': 192, 'total_tokens': 2910}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [22 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Coverage Criteria for Deep Learning Systems\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: InourstudiedDNNs,CT-guidedtestgenerationthatsystematicallycoverstheCTcoveragetargetsfortheﬁrstseverallayersofDNNsalreadyenablestodetectsuﬃcientadversarialexamplesandlocal-robustnessissues;wewillinvestigatewhetherthisresultscouldgeneralizetootherdatasetandDNNsinourfuturework.  Ourproposedcombinatorialtestingcoveragecriteriaareusefulforadver-sarialexampledetectionandlocal-robustnessanalysis.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Theirtestcriteriahave\f",
      "4L.Maetal.beenevaluatedonsmall-scaleneuralnetworks(withonlyDenselayers,withnomorethan400neurons).DeepGauge[25]proposesacomprehensivesetofnumerical-basedtestingcriteria(e.g.,boundarycoveragecriteria,majorfunc-tionalcoveragecritiera),whoseusefulnessandscalabilityhavebeendemon-stratedonpractical-sizedDNNssuchasResNet-50(withnear200layersand100,000neurons).Besidestheseinitialworkonproposingtestingcoveragecrite-riaforDNNs,DeepMutation[24]exploresandproposestheﬁrstmutationtestingtechniqueforDNNs,itprovidesageneralmutationtestingframework,includingbothsource-levelmutationtestingandmodel-levelmutationtesting.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: CombinatorialTestingforDeepLearningSystems3–WealsoprovideageneralCTcoverageguidedtestgenerationtechniqueforDLsystems.–WeperformextensiveempiricalstudiesusinglinearprogrammingbasedtestgenerationtodemonstratetheusefulnessoftheproposedDLtestingtech-niques.  WehighlightthatCTcanprovideapromisingavenuefortestingDLsystems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Asmentionedinthelastsection,DeepCTproposesageneralcombinatorialcoverageguidedtestingmethodforDNNs,thetestgenerationtechniquecouldbesubstitutedbyothertechniquesaswell.  Thepurposeofthisworkthatadoptsaconstraint-basedapproachistodemonstratetheusefulnessoftheproposedCTcoveragecriteriafortestingDNNs.  However,weﬁndthatthenumberofneuronsisoftenquitelargeinpracticalDLsystems,anditwouldgreatlyhindertheconstraint-basedtestgenerationtechniques.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: ArXive-prints(May2018)25.Ma,L.,Juefei-Xu,F.,Zhang,F.,Sun,J.,Xue,M.,Li,B.,Chen,C.,Su,T.,Li,L.,Liu,Y.,Zhao,J.,Wang,Y.:Deepgauge:Multi-granularitytestingcriteriafordeeplearningsystems.  CoRRabs/1803.07519(2018),http://arxiv.org/abs/1803.0751926.McMinn,P.:Search-basedsoftwaretesting:Past,presentandfuture.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Researchondesign-ingtestcoverageandtestcasegenerationforDLisemerging[30,34].However,theseworkmainlyrelyonprobingtheaccuracyontestdatawhicharerandomlydrawnfrommanuallylabeleddatasetsandadhocsimulations[38],andsomeofthemfocusonsmall-scaleneuralnetworks[34].Besides,neuroncoveragecriteriahavebeenproposedrecentlyandhaveempiricallydemonstratedtobeeﬀectiveforguidingtestcasegeneration[25],whilethesynergyeﬀectsofneuronswithinandacrosslayers(e.g.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Speciﬁcally,fortestingDNNs,Deep-Xplore[30]proposesawhite-boxdiﬀerentialtestingalgorithmtosystemati-callygenerateadversarialexamplesthatcoverallneuronsinthenetwork.  Deep-Cover[34]proposestheMC/DCtestcriteriaforDNNs.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: WeadapttheconceptinCTandproposeasetofcoveragecriteriaforDLsystems,aswellasaCTcoverageguidedtestgenerationtechnique.OurevaluationdemonstratesthatCTprovidesapromisingavenuefortestingDLsystems.  WefurtherposeseveralopenquestionsandinterestingdirectionsforcombinatorialtestingofDLsys-tems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: WeagainemphasizethatourresearchistheﬁrsttoadapttheconceptofCT,provideCTcoverageguidedtestgeneration,andperformanempiricalstudyto-wardevaluatingtherobustnessofDLsystemsusingCT.WethushopethatapplyingCTtoDLsystemsmayconstituteaseminalforesightbuiltonourevaluationresults,andinparallelshedlightontheconstructionofmoreCTcoveragecriteriaandscalabletestgenerationtechniquestowardsachievingro-bustreal-worldDLapplications.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 3 level markdown title (`###`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2628, 'completion_tokens': 140, 'total_tokens': 2768}, 'model_name': 'gpt-3.5-turbo'}\n",
      "INFO:metaanalyser.chains.sr:Writing sections: [23 / 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SRSectionChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a research scientist and intereseted in Software Engineering, Computation and Language and Artificial Intelligence. You are working on writing a systematic review regarding \"programming testing arxiv\".\n",
      "\n",
      "The outline of the systematic review is as follows:\n",
      "\n",
      "-----\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
      "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
      "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
      "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
      "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
      "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
      "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
      "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
      "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
      "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
      "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
      "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
      "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
      "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
      "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
      "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
      "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
      "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
      "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
      "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
      "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
      "Human: Write the \"Conclusion\" section of this systematic review based on the following list of snippets or abstracts of relative papers.\n",
      "\n",
      "-----\n",
      "Title: Metamorphic testing: a new approach for generating next test cases\n",
      "citation_id: 1\n",
      "Text: In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.\n",
      "\n",
      "\n",
      "Title: Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
      "citation_id: 2\n",
      "Text: Benchmark datasets have a significant impact on accelerating research in programming language tasks. In this paper, we introduce CodeXGLUE, a benchmark dataset to foster machine learning research for program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems.\n",
      "\n",
      "\n",
      "Title: Neuro-symbolic program synthesis\n",
      "citation_id: 3\n",
      "Text: Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training.\n",
      "\n",
      "\n",
      "Title: Test case generation for program repair: A study of feasibility and effectiveness\n",
      "citation_id: 4\n",
      "Text: Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches. In this paper, we investigate the feasibility and effectiveness of test case generation in alleviating the overfitting issue. We propose two approaches for using test case generation to improve test suite based repair, and perform an extensive evaluation of the effectiveness of the proposed approaches in enabling better test suite based repair on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. We identify the problems related with the ineffectiveness, and anticipate that our results and findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
      "\n",
      "\n",
      "Title: Combinatorial testing for deep learning systems\n",
      "citation_id: 5\n",
      "Text: Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.\n",
      "-----\n",
      "\n",
      "This systematic review should adhere to the following overview:\n",
      "\n",
      "Title: A Systematic Review of Programming Testing Arxiv\n",
      "Points:\n",
      "  - Metamorphic testing as a new approach for generating next test cases\n",
      "  - Codexglue as a machine learning benchmark dataset for code understanding and generation\n",
      "  - Neuro-symbolic program synthesis as a novel technique to overcome limitations of neural architectures for program induction\n",
      "  - Test case generation for program repair as a study of feasibility and effectiveness\n",
      "  - Combinatorial testing for deep learning systems as a promising avenue for testing DL systems\n",
      "Overview: This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
      "\n",
      "Write the \"Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\" section with respect to this overview. Write the text in markdown format. The title of this section should bu suffixed with 2 level markdown title (`##`). The text of the section should be based on a snippet or abstact and should be clearly cited. The citation should be written at the end of the sentence in the form `[^<ID>]` where `ID` refers to the citation_id.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metaanalyser.chains.base:LLM utilization: {'token_usage': {'prompt_tokens': 2525, 'completion_tokens': 413, 'total_tokens': 2938}, 'model_name': 'gpt-3.5-turbo'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "CPU times: user 33 s, sys: 1.13 s, total: 34.2 s\n",
      "Wall time: 12min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from metaanalyser.chains import SRChain\n",
    "\n",
    "query = \"programming testing arxiv\"\n",
    "chain = SRChain(llm=llm, verbose=True)\n",
    "\n",
    "result = chain.run({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e098158-bcf1-4eaa-807e-a5f0f17b3d12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# A Systematic Review of Programming Testing Arxiv\n",
       "\n",
       "This systematic review explores the field of programming testing arxiv, which aims to solve the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
       "\n",
       "## Table of contents\n",
       "\n",
       "1. Introduction: This section provides an overview of the field of programming testing arxiv and its importance in solving the problem of software errors.\n",
       "2. Metamorphic Testing for Generating Next Test Cases: This section discusses the concept of metamorphic testing and its potential to reveal software errors that are left undetected in successful test cases. It also explores the limitations of current software testing techniques and proposes a novel test case selection technique.\n",
       "    1. Background: This subsection provides a brief history of software testing and its importance in software development.\n",
       "    2. Metamorphic Testing: This subsection explains the concept of metamorphic testing and how it can be used to generate new test cases from successful ones.\n",
       "    3. Limitations of Current Software Testing Techniques: This subsection explores the limitations of current software testing techniques and how metamorphic testing can augment their effectiveness.\n",
       "    4. Proposed Test Case Selection Technique: This subsection discusses the proposed test case selection technique and how it can help uncover software errors in the production phase.\n",
       "3. Codexglue for Machine Learning Research: This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. It also discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
       "    1. Background: This subsection provides a brief history of benchmark datasets and their importance in machine learning research.\n",
       "    2. CodeXGLUE: This subsection introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation.\n",
       "    3. Impact of Benchmark Datasets on Accelerating Research: This subsection discusses the impact of benchmark datasets on accelerating research in programming language tasks.\n",
       "4. Neuro-Symbolic Program Synthesis: This section proposes a novel technique, Neuro-Symbolic Program Synthesis, to overcome the limitations of neural architectures for program induction. It also explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
       "    1. Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
       "    2. Neuro-Symbolic Program Synthesis: This subsection explains the concept of Neuro-Symbolic Program Synthesis and how it can overcome the limitations of neural architectures for program induction.\n",
       "    3. Automatically Constructing Computer Programs: This subsection explains how the proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
       "5. Test Case Generation for Program Repair: This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. It also proposes two approaches for using test case generation to improve test suite based repair.\n",
       "    1. Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
       "    2. Feasibility and Effectiveness of Test Case Generation: This subsection investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques.\n",
       "    3. Proposed Approaches for Using Test Case Generation: This subsection proposes two approaches for using test case generation to improve test suite based repair.\n",
       "6. Combinatorial Testing for Deep Learning Systems: This section explores the challenges of testing deep learning systems and proposes combinatorial testing as a promising avenue for testing such systems. It also adapts the concept of combinatorial testing and proposes a set of coverage criteria for deep learning systems.\n",
       "    1. Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
       "    2. Combinatorial Testing: This subsection explains the concept of combinatorial testing and how it can be used to reduce the testing space while obtaining relatively high defect detection abilities.\n",
       "    3. Coverage Criteria for Deep Learning Systems: This subsection proposes a set of coverage criteria for deep learning systems.\n",
       "7. Conclusion: This section summarizes the main findings of the systematic review and discusses future research directions in programming testing arxiv.\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Software errors can cause significant damage to the production system and lead to financial losses. Therefore, software testing is an essential part of software development to ensure the quality of the software. However, the limitations of current software testing techniques have been observed [^1]. Firstly, successful test cases that do not reveal software errors are usually not further investigated, although they may contain useful information for revealing software errors. Secondly, errors may still exist in the software even after extensive testing in the development phase, and techniques for uncovering software errors in the production phase are seldom addressed in the literature. Thirdly, the availability of test oracles is pragmatically unattainable in most situations, but it is generally assumed in conventional software testing techniques. \n",
       "\n",
       "To address these limitations, the field of programming testing arxiv has emerged, which aims to develop new techniques for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, and testing deep learning systems [^1][^2][^3][^4][^5]. This systematic review explores the field of programming testing arxiv and its importance in solving the problem of software errors. It covers the historical background of the field and its future development. The review includes five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems.\n",
       "\n",
       "## Metamorphic Testing for Generating Next Test Cases\n",
       "\n",
       "Metamorphic testing is a new approach for generating next test cases that aims to reveal software errors that are left undetected in successful test cases [^1]. The current artifacts of software testing have limitations, including the assumption that successful test cases that do not reveal software errors are not further investigated. However, these successful test cases may still contain useful information for revealing software errors [^1]. Additionally, errors may still exist in the software even after extensive testing has been conducted in the development phase, and techniques for uncovering software errors in the production phase are seldom addressed in the literature [^1]. \n",
       "\n",
       "Metamorphic testing proposes a novel test case selection technique that derives new test cases from the successful ones, augmenting the effectiveness of existing test selection strategies [^1]. The selection aims to reveal software errors that are possibly left undetected in successful test cases generated using some existing strategies [^1]. The proposed technique can also help uncover software errors in the production phase and can be used in the absence of test oracles [^1]. \n",
       "\n",
       "The limitations of current software testing techniques can be overcome by using metamorphic testing, which generates new test cases from successful ones and helps uncover software errors that are left undetected [^1].\n",
       "\n",
       "### Background: This subsection provides a brief history of software testing and its importance in software development.\n",
       "\n",
       "Software testing is an essential part of software development that aims to identify and correct errors in software systems. As stated by [^1], software testing involves constructing a set of test cases according to some predefined selection criteria and examining the software against these test cases. The importance of software testing lies in its ability to ensure the quality and reliability of software systems. However, despite the extensive testing conducted during the development phase, errors may still exist in the software [^1]. These errors, if left undetected, may eventually cause damage to the production system. Therefore, the study of techniques for uncovering software errors in the production phase is crucial. Additionally, the availability of test oracles is pragmatically unattainable in most situations [^1]. However, the availability of test oracles is generally assumed in conventional software testing techniques. Therefore, new approaches for generating test cases and augmenting the effectiveness of existing test selection strategies are needed to improve the quality and reliability of software systems.\n",
       "\n",
       "### Metamorphic Testing\n",
       "\n",
       "Metamorphic testing is a new approach for generating next test cases from successful ones [^1]. The technique aims to reveal software errors that are possibly left undetected in successful test cases generated using some existing strategies. The proposed technique augments the effectiveness of existing test selection strategies and helps uncover software errors in the production phase. The selection of new test cases is based on the output of the successful test cases, and the technique can be used in the absence of test oracles [^1]. Metamorphic testing can be used with other test case selection strategies and can be combined with program checkers to suggest further testing [^1]. The approach requires problem domain knowledge, and a domain-specific methodology should be developed to facilitate the development of such a methodology [^1].\n",
       "\n",
       "### Limitations of Current Software Testing Techniques\n",
       "\n",
       "Current software testing techniques have limitations that can result in undetected errors in software systems [^1][^5]. Successful test cases that do not reveal software errors are usually not further investigated, even though they may contain useful information for revealing software errors [^1]. Additionally, errors may still exist in the software even after extensive testing has been conducted in the development phase, and techniques for uncovering software errors in the production phase are seldom addressed in the literature [^1]. Furthermore, the availability of test oracles is pragmatically unattainable in most situations, but it is generally assumed in conventional software testing techniques [^1]. However, metamorphic testing can augment the effectiveness of existing test selection strategies by deriving new test cases from successful ones, which aims at revealing software errors that are possibly left undetected in successful test cases [^1]. The proposed technique can also help uncover software errors in the production phase and can be used in the absence of test oracles [^1].\n",
       "\n",
       "### Proposed Test Case Selection Technique\n",
       "\n",
       "In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. However, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied [^1]. To address this issue, a novel test case selection technique is proposed that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles [^1].\n",
       "\n",
       "## Codexglue for Machine Learning Research\n",
       "\n",
       "This section introduces CodeXGLUE, a benchmark dataset for machine learning research in program understanding and generation. CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison [^2]. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems. Benchmark datasets have a significant impact on accelerating research in programming language tasks [^2].\n",
       "\n",
       "### Background: A Brief History of Benchmark Datasets and Their Importance in Machine Learning Research\n",
       "\n",
       "Benchmark datasets have played a significant role in accelerating research in programming language tasks and machine learning. As stated by [^2], benchmark datasets provide a platform for the development and validation of new methods that can be applied to various program understanding and generation problems. They also enable researchers to compare the performance of different models and algorithms on a standardized set of tasks. Benchmark datasets have been used in various fields, including computer vision, natural language processing, and speech recognition, to name a few. The availability of such data and baselines can help researchers to develop new methods and improve the state-of-the-art in the field.\n",
       "\n",
       "### CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation\n",
       "\n",
       "CodeXGLUE is a benchmark dataset for machine learning research in program understanding and generation [^2]. It includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison. CodeXGLUE also features three baseline systems, including the BERT-style, GPT-style, and Encoder-Decoder models, to make it easy for researchers to use the platform. The availability of such data and baselines can help the development and validation of new methods that can be applied to various program understanding and generation problems. Benchmark datasets have a significant impact on accelerating research in programming language tasks, and CodeXGLUE is the first diversified benchmark dataset that can be applied to various code intelligence problems [^2].\n",
       "\n",
       "### Impact of Benchmark Datasets on Accelerating Research\n",
       "\n",
       "Benchmark datasets have been shown to have a significant impact on accelerating research in programming language tasks [^2]. The availability of benchmark datasets such as CodeXGLUE can help the development and validation of new methods that can be applied to various program understanding and generation problems. The success of benchmark datasets such as ImageNet for computer vision and GLUE for natural language understanding has demonstrated the importance of diversified benchmark datasets in the growth of applied AI research [^2].\n",
       "\n",
       "## Neuro-Symbolic Program Synthesis\n",
       "\n",
       "Neuro-Symbolic Program Synthesis is a novel technique proposed to overcome the limitations of neural architectures for program induction [^3]. This technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. The approach is based on two novel neural modules. The first module, called the cross-correlation I/O network, produces a continuous representation of the set of input-output examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), synthesizes a program by incrementally expanding partial programs. The R3NN model is not only able to construct programs from new input-output examples but also able to construct new programs for tasks that it had never observed before during training. This technique is motivated by the need for model interpretability and scalability to multiple tasks [^3].\n",
       "\n",
       "### Background: This subsection provides a brief history of neural architectures for program induction and their limitations.\n",
       "\n",
       "Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. These architectures are able to learn mappings that generalize to new test inputs. However, they have several limitations. Firstly, they are computationally expensive and hard to train. Secondly, a model has to be trained for each task (program) separately. Thirdly, it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network) [^3]. These limitations have motivated the development of novel techniques such as Neuro-Symbolic Program Synthesis, which aims to overcome these problems and automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time.\n",
       "\n",
       "### Neuro-Symbolic Program Synthesis\n",
       "\n",
       "Neuro-Symbolic Program Synthesis is a novel technique proposed by Parisotto et al. to overcome the limitations of neural architectures for program induction [^3]. The existing neural architectures for program induction are computationally expensive, hard to train, and require a separate model for each task. Moreover, it is difficult to interpret or verify the correctness of the learned mapping. Neuro-Symbolic Program Synthesis can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. The proposed method is based on two novel neural modules: the cross-correlation I/O network and the Recursive-Reverse-Recursive Neural Network (R3NN). The cross-correlation I/O network produces a continuous representation of the set of input-output examples, while the R3NN synthesizes a program by incrementally expanding partial programs. The effectiveness of the approach is demonstrated by applying it to the domain of regular expression-based string transformations. The R3NN model is not only able to construct programs from new input-output examples but also able to construct new programs for tasks that it had never observed before during training [^3].\n",
       "\n",
       "### Automatically Constructing Computer Programs\n",
       "\n",
       "Neuro-Symbolic Program Synthesis is a novel technique proposed to overcome the limitations of neural architectures for program induction [^3]. The proposed technique can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. The approach is based on two novel neural modules. The first module, called the cross correlation I/O network, produces a continuous representation of the set of input-output examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), synthesizes a program by incrementally expanding partial programs. The effectiveness of the approach has been demonstrated by applying it to the domain of regular expression based string transformations. The R3NN model is not only able to construct programs from new input-output examples but also able to construct new programs for tasks that it had never observed before during training [^3].\n",
       "\n",
       "## Test Case Generation for Program Repair\n",
       "\n",
       "This section investigates the feasibility and effectiveness of test case generation in alleviating the overfitting issue in test suite based program repair techniques. Test-suites are typically inadequate for completely specifying the expected behavior of the program under repair, which leads to overfitting patches that pass the test suite but may be incorrect. To address this issue, two approaches for using test case generation to improve test suite based repair are proposed in [^4]. The first approach works with generate-and-validate techniques (MinImpact), and the second one for synthesis-based techniques (UnsatGuided). The proposed approaches are evaluated on 224 bugs of the Defects4J repository, and the results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. The study identifies the problems related to the ineffectiveness and anticipates that the findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems.\n",
       "\n",
       "### Background: This subsection provides a brief history of program repair techniques and their limitations.\n",
       "\n",
       "Program repair techniques aim to automatically fix software bugs. Among the many different kinds of program repair techniques, one widely studied family of techniques is called test suite based repair. Test-suites are in essence input-output specifications and are therefore typically inadequate for completely specifying the expected behavior of the program under repair. Consequently, the patches generated by test suite based program repair techniques pass the test suite, yet may be incorrect. Patches that are overly specific to the used test suite and fail to generalize to other test cases are called overfitting patches [^4]. The limitations of test suite based repair techniques have led to the investigation of the feasibility and effectiveness of test case generation in alleviating the overfitting issue.\n",
       "\n",
       "### Feasibility and Effectiveness of Test Case Generation\n",
       "\n",
       "Test suite based repair techniques suffer from the overfitting issue, where the generated patches may be overly specific to the used test suite and fail to generalize to other test cases. In order to alleviate this issue, test case generation has been proposed as a potential solution [^4]. This subsection investigates the feasibility and effectiveness of test case generation in improving test suite based repair techniques. The authors propose two approaches for using test case generation and perform an extensive evaluation on 224 bugs of the Defects4J repository. The results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. The authors identify the problems related to the ineffectiveness and anticipate that their findings will lead to future research to build test-case generation techniques that are tailored to automatic repair systems [^4].\n",
       "\n",
       "### Proposed Approaches for Using Test Case Generation\n",
       "\n",
       "Test suite based repair techniques generate patches that pass the test suite but may be incorrect, leading to overfitting patches. In order to alleviate this issue, test case generation can be used to improve test suite based repair. Two approaches have been proposed for this purpose [^4]:\n",
       "\n",
       "1. **MinImpact:** This approach is suitable for generate-and-validate techniques that can enumerate patches. It uses an evolutionary approach to derive test suites that maximize code coverage and generates assertions that encode the current behavior of the program. The aim is to use additional automatically generated tests to guide the patch generation process towards generating patches that are less likely to be overfitting.\n",
       "\n",
       "2. **UnsatGuided:** This approach is suitable for synthesis-based techniques. It uses a constraint solver to synthesize patches that satisfy the given test suite. The aim is to use additional automatically generated tests to guide the synthesis process towards generating patches that are less likely to be overfitting.\n",
       "\n",
       "These approaches have been evaluated on 224 bugs of the Defects4J repository, and the results indicate that test case generation can change the resulting patch, but is not effective at turning incorrect patches into correct ones. The ineffectiveness is attributed to the limitations of the generate-and-validate and synthesis-based techniques used in the study. Future research is anticipated to build test-case generation techniques that are tailored to automatic repair systems. [^4]\n",
       "\n",
       "## Combinatorial Testing for Deep Learning Systems\n",
       "\n",
       "Deep learning (DL) systems have been widely applied in various applications due to their high accuracy, but their robustness has recently received great concerns [^5]. Testing techniques could help to evaluate the robustness of a DL system and detect vulnerabilities at an early stage. However, the main challenge of testing such systems is that their runtime state space is too large [^5]. Combinatorial testing (CT) is an effective testing technique for traditional software to reduce the testing space while obtaining relatively high defect detection abilities. In an exploratory study of CT on DL systems, a set of coverage criteria for DL systems and a CT coverage guided test generation technique were proposed [^5]. The evaluation demonstrated that CT provides a promising avenue for testing DL systems. The proposed combinatorial testing coverage criteria are useful for adversarial example detection and local-robustness analysis [^5].\n",
       "\n",
       "### Background: This subsection provides a brief history of deep learning systems and their challenges in testing.\n",
       "\n",
       "Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences [^5]. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible [^5].\n",
       "\n",
       "### Combinatorial Testing\n",
       "\n",
       "Combinatorial testing (CT) is a well-established and successful technique in traditional software testing that aims to reduce the testing space while obtaining relatively high defect detection abilities [^5]. CT focuses on testing the interactions of inputs rather than exhaustively searching all the combinations of input space. This technique has been successfully applied to testing different configurable software systems, as most faults are caused by interactions involving only a few parameters [^5]. However, CT is limited in handling various constraints and is not directly applicable to deep learning (DL) systems due to their massive runtime state space [^5]. \n",
       "\n",
       "In this paper, an exploratory study of CT on DL systems is performed. The concept of CT is adapted, and a set of coverage criteria for DL systems is proposed, as well as a CT coverage-guided test generation technique [^5]. The evaluation results demonstrate that CT provides a promising avenue for testing DL systems [^5].\n",
       "\n",
       "### Coverage Criteria for Deep Learning Systems\n",
       "\n",
       "Combinatorial testing (CT) has been proposed as a promising avenue for testing deep learning (DL) systems. To reduce the testing space while obtaining relatively high defect detection abilities, a set of coverage criteria for DL systems has been proposed [^5]. These criteria are useful for adversarial example detection and local-robustness analysis. The proposed CT coverage criteria have been evaluated on small-scale neural networks with only dense layers, with no more than 400 neurons. The usefulness and scalability of the proposed criteria have also been demonstrated on practical-sized DL systems such as ResNet-50 with near 200 layers and 100,000 neurons [^5].\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In this systematic review, we have explored the field of programming testing arxiv and its importance in solving the problem of software errors. We have covered five papers that discuss new approaches for generating test cases, benchmark datasets for machine learning research, novel techniques for program synthesis, feasibility and effectiveness of test case generation for program repair, and combinatorial testing for deep learning systems. \n",
       "\n",
       "Metamorphic testing has been proposed as a new approach for generating next test cases that can reveal software errors left undetected in successful test cases [^1]. CodeXGLUE has been introduced as a benchmark dataset for machine learning research in program understanding and generation, which can help accelerate research in programming language tasks [^2]. Neuro-symbolic program synthesis has been proposed as a novel technique to overcome the limitations of neural architectures for program induction [^3]. Test case generation for program repair has been investigated for its feasibility and effectiveness in alleviating the overfitting issue in test suite based program repair techniques [^4]. Combinatorial testing has been explored as a promising avenue for testing deep learning systems, and a set of coverage criteria for deep learning systems has been proposed [^5].\n",
       "\n",
       "Future research directions in programming testing arxiv include exploring the potential of metamorphic testing in uncovering software errors in the production phase, developing new benchmark datasets for machine learning research, improving the effectiveness of test case generation for program repair, and further investigating the feasibility and effectiveness of combinatorial testing for deep learning systems. Overall, the papers covered in this systematic review provide valuable insights and directions for future research in programming testing arxiv. \n",
       "\n",
       "[^1]: 1. Metamorphic testing: a new approach for generating next test cases\n",
       "[^2]: 2. Codexglue: A machine learning benchmark dataset for code understanding and generation\n",
       "[^3]: 3. Neuro-symbolic program synthesis\n",
       "[^4]: 4. Test case generation for program repair: A study of feasibility and effectiveness\n",
       "[^5]: 5. Combinatorial testing for deep learning systems\n",
       "\n",
       "## References\n",
       "[^1]: [Chen, Tsong Y., Shing C. Cheung, and Shiu Ming Yiu. \"Metamorphic testing: a new approach for generating next test cases.\" arXiv preprint arXiv:2002.12543 (2020).](https://arxiv.org/abs/2002.12543)\n",
       "\n",
       "[^2]: [Lu, Shuai, et al. \"Codexglue: A machine learning benchmark dataset for code understanding and generation.\" arXiv preprint arXiv:2102.04664 (2021).](https://arxiv.org/abs/2102.04664)\n",
       "\n",
       "[^3]: [Parisotto, Emilio, et al. \"Neuro-symbolic program synthesis.\" arXiv preprint arXiv:1611.01855 (2016).](https://arxiv.org/abs/1611.01855)\n",
       "\n",
       "[^4]: [Yu, Zhongxing, et al. \"Test case generation for program repair: A study of feasibility and effectiveness.\" arXiv preprint arXiv:1703.00198 (2017).](https://arxiv.org/abs/1703.00198)\n",
       "\n",
       "[^5]: [Ma, Lei, et al. \"Combinatorial testing for deep learning systems.\" arXiv preprint arXiv:1806.07723 (2018).](https://arxiv.org/abs/1806.07723)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68e45f1-011e-4837-b623-fc94638a3c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"../examples/{query}.md\", \"wt\") as f:\n",
    "    f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae13cd-64d5-4d1d-84ca-c994055ef4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
